
\chapter{Background and Related Work}

\section{Type Systems}

%Exploring sophisticated type systems and their seamless integration into programming languages is a thoroughly researched field. From System $\FMu$  up to System $\FMuOmega$ , how far can we go until these systems are no longer suitable for compilers.

Type systems are a fundamental tool in programming language theory, providing a framework to categorize and constrain the behavior of programs, while types define the kind of data a program manipulates, e.g., integers, booleans, strings. 

Type systems manage a program's data types through type checking, which can be classified as either static---occurs at compile time, where the types of all variables and expressions are known and checked before the program runs---or dynamic---occurs at run-time, where the types are checked as the program executes. 

Over the course of time, type systems have evolved to become more expressive, moving from simple type assignments to more powerful systems that support polymorphism, recursion, and structured communication patterns.

System $F$, also called the polymorphic lambda calculus, extends the simply typed lambda calculus with \textit{parametric polymorphism}, which allows functions to be written generically and applied to arguments of any type. [ref] In the simply typed lambda calculus, every function has a concrete type. For instance, a function that operates on integers has the type $\function \Int \Int$. However, in order to express a function that operates on a lists of arbitrary types, we would need a separate function for each of the types in the list. To overcome this limitation, System $F$ allowed functions to be polymorphic. For example, the identity function, written $\lambda X. \lambda x:X. x$, returns its argument unchanged, working uniformly for any type---and when instantiated to $\Int$, the result is the identity function on integers, whereas when applied to $Bool$, the result is the identity function on booleans. This is possible through the introduction of type \textit{abstractions}---functions are parameterized by types---and type \textit{applications}---types are passed as arguments to functions.

While System $F$ is a powerful system for expressing parametric polymorphism, it lacks a direct way to express recursive types, which are essential for defining more complex structures and functions that rely on self-reference. Recursive types are particularly important for defining data structures like lists, trees, and infinitely repeating processes.

System $\FMu$ comes as an extension of System $F$ with the addition of \textit{recursion}, denoted by $\mu X.T$, which allows a type $\TT$ to refer to itself through the variable $X$. When adding recursion, type systems must choose how to approach recursive types: a type can be either \textit{equirecursive} or \textit{isorecursive}.
The difference lies on the relation between the type and its' (one-step) unfold. Are $\mu X.T$ and its' unfold ,$T. \mu X.T$, the same type? Equirecursive types say yes. They represent the same infinite tree and therefore are interchangeable when type checking. However, implementing such type checking algorithms requires additional work and attention to guarantee termination. On the other hand, isorecursive types say they are different. Therefore, they are not interchangeable but only isomorphic. 

By allowing recursion at the type level, System $\FMu$ significantly increases the expressiveness of the type system, making it capable of representing potentially infinite structures. However, now care must be taken to ensure that recursive functions terminate, which leads to type systems often incorporating additional rules or constraints to ensure \textit{termination}. Without guarantees of termination, recursive types could lead to non-terminating computations, i.e., infinite recursions, which can make programs unreliable.  

%\todo{note about grammar, pushdown automata, corresponding to the system.}

System $\FMuSemi$ builds on top of System $\FMu$ by incorporating \textit{session types} into the type system. This extension is designed to model structured communication between concurrent processes, ensuring that communication follows a well-defined protocol. 

\section{Session Types}

Session types offer a formal way to describe communication protocols. They ensure that all participants in a communication process adhere to the agreed protocol, improving both safety and expressiveness. This concept emerged in the early 1990s from the fields of process calculi and type theory, particularly building upon Milner's work on the pi-calculus.[ref] Its main purpose was to bring type-level guarantees to communication protocols.

In a programming language, \textit{types} describe the structure of data (e.g., integers, strings) and session types extend this idea to describe communication patterns. They define the order and type of messages exchanged during an interaction, through a communication channel. 
The following simple protocol is finite: a process might want to send an integer, then receive an integer and finally terminate. This protocol can be described by the session types $S = !\Int.?\Int.\End$---we first send an integer, followed by receiving an integer and finally terminate the session through the type $\End$, which closes the communication channel. The order in which the messages (types) are sent is guaranteed through a sequential composition expressed by the $.$ operator.

Communication typically involves two parties---a sender and a receiver---and for a protocol to function correctly, the session types of these parties must be dual. \textit{Duality} is the relationship between two session types that allows them to correctly engage in a protocol. For any session type describing one side of the communication (let us say the client), there is a dual session type that describes the other side (the server).  For example, the session type $S = \OUTn\Int$ describes sending an integer and its dual session type is to receive an integer, $\dual{S} = \INn\Int$.  

Some, more advanced, communication patterns involve branching, where a process might choose, from a set of choices, how to continue the communication. 

$\intchoice\rchannel{isEven}{!Int.?Bool.End}{isZero}{!Int.?Bool.End}$

The previous type represents a protocol (from the client perspective) that offers two operations on integers: it checks whether an integer is even or odd, and it checks whether an integer is zero. Session types are able to express such protocols by offering choice operations---either internal, $\&$, or external, $+$---to the client, which in turn selects how to proceed with the communication: if the client wants to check if an integer is even, it must select the branch $isEven$.



One of the key advantages of session types is that they enable \textit{type-safe communication}. This means that at compile time, the system can check whether the communication patterns follow the prescribed protocol, preventing errors like sending a message of a wrong type. Session types can also help ensure \textit{deadlock freedom}, meaning the system avoids situations where two parties wait indefinitely for each other to send or receive a message.


Session types also have limitations---they are tail recursive---not being able to describe expressive types that refer to themselves at any given point of a sequential composition rather than at the end. For instance, the type $ \typec{\mu S} .\OUTn\TT.\typec{S}$, represents adding $\OUTn\TT$ to the tail $\OUTn\TT\OUTn\TT\OUTn\TT...\typec{\mu S}.\OUTn\TT.\typec{S}$ continuously until the session terminates. 

\todo{talk about: "The equivalence of session types is the equivalence of binary trees." }

The lack of expressiveness with the increasing complexity of communication protocols in modern systems lead us to context-free session types.

%\todo{mention fmu and fmu. can be represented by finite-state automata somewhere.}
\section{Context-free Session Types}

Context-free session types break free from tail recursion by introducing the sequential composition operator $\Semi$ and the type $\Skip$---neutral element of sequential composition---which represents a protocol with no actions. For instance, one might choose to write $S;!T$ or $!T;S;!T$ where recursion is found in the head or middle of the type.  

\todo{contexto para paragrafo.}

For example, types $\Skip\Semi\TT$ and $\TT$ are equivalent but the same is not true for the equivalence of the trees they represent. 

\begin{center}
\begin{tikzpicture}
    \matrix (m) [matrix of math nodes, nodes in empty cells,
                 row sep=2em, column sep=3em,
                 nodes={anchor=center}]
    {
        & \Semi & \\
        \Skip & & \typec{T} \\
    };

    \draw[->] (m-1-2) -- (m-2-1); % \; to skip
    \draw[->] (m-1-2) -- (m-2-3); % \; to T
\end{tikzpicture}
\end{center}

Also, one could naively think the problem lies solely on the neutral element $\Skip$ but such saying is not true: $\TT\Semi(\typec{U}\Semi\typec{V})$ and $(\TT\Semi\typec{U})\Semi\typec{V}$ are equivalent, but their trees are not. 

\begin{center}
\begin{tikzpicture}
    \matrix (m) [matrix of math nodes, nodes in empty cells,
                 row sep=2em, column sep=3em,
                 nodes={anchor=center}]
    {
        & \Semi && \\
        \typec{T} & & \Semi &\\
        & \typec{U} & & \typec{U}\\
    };

    \draw[->] (m-1-2) -- (m-2-1); 
    \draw[->] (m-1-2) -- (m-2-3); 
    \draw[->] (m-2-3) -- (m-3-2); 
    \draw[->] (m-2-3) -- (m-3-4); 
\end{tikzpicture}
\end{center}

\begin{center}
\begin{tikzpicture}
    \matrix (m) [matrix of math nodes, nodes in empty cells,
                 row sep=2em, column sep=3em,
                 nodes={anchor=center}]
    {
        &&  \Semi  \\
        & \Semi & & \typec{V}\\
        \typec{T} &&  \typec{U}\\
    };

    \draw[->] (m-1-3) -- (m-2-2); 
    \draw[->] (m-1-3) -- (m-2-4); 
    \draw[->] (m-2-2) -- (m-3-1); 
    \draw[->] (m-2-2) -- (m-3-3); 

\end{tikzpicture}
\end{center}

\todo{put the trees side by side and add caption.}

%The recursive type $\tmuinfix{\alpha}{\skind}{\extchoice\rchannel{\leafl}{\Skip}{\nodel}{\alpha\Semi\ \INp\Int\Semi\ \alpha}}\Semi\End_{\typec{?}}$ describes a protocol for safely streaming integer trees on a channel. The channel presents an external choice $\extchoice$ with two labels: if the continuation of the channel is $\leafl$, then no communication occurs but the channel is still open for further composition whereas, if the continuation of the channel is $\nodel$, then we have a left subtree, followed by an integer and a right subtree. When the whole tree is received, the channel is closed. 

%It is also important to distinguish type $\End_{\typec{?}}$ from $\Skip$---the former represents the closure of a channel, $\typec{?}$ standing for either $\Wait$ or its' dual $\Close$, where no further communication is possible, while the latter allows continuing the communication where its' dual is himself.

Context-free session types are more expressive than their regular counterparts, covering a wider range of communication protocols and being representable by \textit{context-free grammars}.
Grammars can be specified by tuples of the form $(\mathcal{T, N}, X, \mathcal{R})$, where: 
\begin{enumerate}
    \item $\mathcal{T}$ is a finite set of terminal symbols such as $a, b, c$; 
    \item $\mathcal{N}$ is a finite set of non-terminal symbols, $X, Y, Z$;
    \item $X$ is the starting symbol. $X$ must be an element of $\mathcal{N}$, $X\in\mathcal{N}$;
    \item $\mathcal{R}$ is a finite set of productions, where $P \subseteq N \times (T \cup N)^*$. 
\end{enumerate}
A production rule in $\mathcal{R}$ is written as $X \rightarrow \sigma$: the left side of the arrow must be a non-terminal, $X\in\mathcal{N}$, while the right side must be a word, such that $\sigma\in(\mathcal{N}\cup\mathcal{T})^*$. Also, $\sigma$ can be the empty word. We are particularly interested in simple grammars in Greibach normal form [ref]. Grammars are in \textit{Greibach normal form} if production rules take form as $X \rightarrow a\gamma$, where $X\in\mathcal{N}$, $a\in\mathcal{T}$ and $\gamma\in\mathcal{N}^*$. Grammars in GNF are \emph{simple} when for every non-terminal and terminal symbol there is at most one production $X \rightarrow a\gamma$ [ref].

These type systems prove interesting to implement since they closely represent programs. Therefore, we want to incorporate these type systems into programming languages.

\section{The FreeST Programming Language}
FreeST [ref], a concurrent functional programming language based on system $F^{\mu;}$, is regulated by context-free session types. Resembling Haskell's syntax, FreeST offers primitives to create channels and communicate trough them.

Typically in programming languages, a value can be used as many times as needed. However, FreeST uses a linear type system: a resource may be used exactly once---represented by $1$---or unrestrictely, meaning a resource can be used zero or more times---represented by a $*$. Session type channels are linear and must be used exactly once. Therefore, linear programming languages help ensure the channels protocols are fulfilled. 

It is also important to note that these channels are heterogeneous: $\OUTn\Int\Semi\INn\Int$ is undoubtedly a session type, while $\Bool\rightarrow\Bool$ is a functional type but what about the polymorphic variable $\alpha$? 
The answer relies on FreeST's kinding system. Kinds are pairs composed of a multiplicity and a base kind. Multiplicities control the number of times a value may be used in a given context, making FreeST a linear programming language, and a base kind distinguishs functional types, $\TT$, from session types, $\typec{S}$. Multiplicities and base kinds have an ordering relation denoted by the following lattice. 

\begin{center}
    \begin{tikzpicture}
    % Define matrix
        \matrix (m) [matrix of math nodes, row sep=3em, column sep=3em]
        {
            & \typec{1T} \\
            \typec{*T} && \typec{1S} \\
            & \typec{*S} \\
        };
        % Draw arrows
        \draw[->] (m-1-2) -- (m-2-1) node[midway, above] {};
        \draw[->] (m-2-1) -- (m-3-2) node[near end, below] {};
        \draw[->] (m-1-2) -- (m-2-3) node[midway, above] {};
        \draw[->] (m-2-3) -- (m-3-2) node[near end, below] {};
    \end{tikzpicture}
\end{center}

%By default, types are of kind *T in FreeST (the most common type in programming).

We use FreeST's syntax freely for the following example for serialisation of a binary tree.

\begin{lstlisting}
data Tree = Leaf | Node Int Tree Tree

type TreeChannel = oplus{Leaf: Skip ,Node: !Int; TreeChannel; TreeChannel}

write: foralla. Tree -> TreeChannel;a -> a
write t c = 
    case t of { 
        Leaf -> select Leaf c, 
        Node x t1 t2 -> select Node c & 
                        send x &  
                        write t1 & 
                        write t2
}

treeSum: foralla. dualof TreeChannel; a -> (Int, a) 
treeSum c = 
    match c with { 
        Leaf c -> (0, c), 
        Node c -> let (x, c) = receive c in
                  let (sl , c) = treeSum c in
                  let (sr, c) = treeSum c in
                  (x + sl + sr , c)
}

\end{lstlisting}

\lstinline{Tree} is a binary tree data type that can be either: a \lstinline{Leaf} (empty node), or a \lstinline{Node} containing an integer value and two subtrees (left and right). \lstinline{TreeChannel} defines a communication protocol type that represents how a tree will be transmitted: if the label \lstinline{Leaf} is selected no communication occurs, but the channel is still open to further communication; if the label \lstinline{Node} is selected then the content of the node is sent, followed by the left subtree and right subtree. 

Then we can implement a function that serializes a tree over a channel: this function takes a \lstinline{Tree} argument and a channel and either selects a Leaf, or selects a Node, sends an integer value and recursively writes the left and right subtree. If we want to sum all the values in a Tree, we can read from a TreeChannel and compute the sum of all the nodes in a Tree. 

%We can see how context-free session types come into play in this example, as the first occurence of TreeChannel on the code would not be possible with only regular session types.

\todo{more examples: mathserver, and the following example.}

\begin{lstlisting}
type Stream a = &{Done: Skip, 
                  More: ?a; Stream a}
\end{lstlisting}

Type \lstinline|Stream| offers two choices: \lstinline|Done| which terminates the communication and \lstinline|More|, that reads a value \lstinline|?a| and iterates.
This type can be used as a parameter for a fold channel type.

\begin{lstlisting}
type Fold a b =  ?(b -> a -> b); ?b;
                    Stream a; !b; Close
\end{lstlisting}
\vspace{3mm}

The type \lstinline|Fold| first receives a folding function followed by the starting element and the elements to fold. We denote the elements we want to fold as a stream, using type \lstinline|Stream|. Then, we send the output of the fold as \lstinline|!b| and close the channel.

Let us look at a function that consumes a \lstinline|Fold| channel.

\begin{lstlisting}
foldServer : foralla.forallb. Fold a b -> Unit
foldServer c = 
    let (f,c) = receive c in 
    let (e,c) = receive c in 
    let (r,c) = foldS @a @b f e c in
    c |> send r |> close
               
foldS : foralla.forallb. (b -> a -> b) -> b 
            -> Stream a; !b; End 
            -> (b, !b;Close)
foldS f e (Done c) = (e,c)
foldS f e (More c) = 
    let (x, c) = receive c in
    foldS @a @b f (f e x) c
\end{lstlisting}
\vspace{3mm}
The first function, \lstinline|foldServer|, consumes the first two arguments of the type \lstinline|Fold| channel, that is, receives the folding function and the starting elements, sends the result and terminates the communication by closing the channel. \lstinline|foldS| consumes the stream of elements to fold until the branch \lstinline|Done| is selected. Then, we send the pair \lstinline|(e,c)|, \lstinline|e| being the output and \lstinline|c| the continuation channel.
Note that \lstinline{x |> f} stands for the inverse function application, that is \lstinline{x |> f |> g = g (f x)}.

Now we need a client for \lstinline|foldServer|. 

\begin{lstlisting}
type TreeC a = &{Leaf: Skip, 
                 Node: TreeC a;?a;TreeC a}
\end{lstlisting}
\vspace{3mm}

The type \lstinline|TreeC| offers two choices: \lstinline|Leaf| which terminates the communication and \lstinline|Node|, that receives the left side sub-tree, the root element of that node as \lstinline|?a| and the right side sub-tree.
A channel that receives trees in a serialized format would have the following type \lstinline|TreeChannel a = TreeC a;Close|.

Next we want to transform our trees from channels to streams. We can write a \lstinline|flatten| function that receives a \lstinline|TreeChannel| and a \lstinline|Stream| and outputs the unused part of the stream.

\begin{lstlisting}
flatten: foralla.forallc. TreeChannel a ->
                (Dual Stream a);c -> c
\end{lstlisting}
\vspace{3mm}

We can finally write our client. This client receives a \lstinline|TreeChannel|, the dual of a \lstinline|Fold| channel and outputs \textbf{\lstinline|True|}, if all the elements in the tree channel are non negative, or false otherwise.

\begin{lstlisting}
allPositive: TreeChannel Int ->
             Dual (Fold Int Bool) 1-> Bool
allPositive t c = 
    let c = send (lambdax:Bool.lambday:Int. x 
                    && y > 0 ) c in
    let c = send True c in
    let c = flatten @Int @?Bool;Wait t c in
    let (x,c) = receive c in
    wait c; x
\end{lstlisting}
\vspace{3mm}

First the client sends the folding function, $\lambda x\colon \textbf{\lstinline|Bool|}.\lambda y\colon\textbf{\lstinline|Int|}.\\ 
x\ \&\&\ y\textgreater 0 $, followed by the starting element  \textbf{\lstinline|True|}. Then we call function \lstinline|flatten|. Next, the client receives the output of the \lstinline|Fold| channel, consumes it and waits for the channel to close, $wait c;\ x$.
Note that syntax $flatten\ @Int\ @?Bool;Wait$ stands for term-level type application. 

We can then run both our server and client, like so:
\begin{lstlisting}
main : Bool
main = 
    let tr = forkWith @(TreeC Int) @() 
                      produce in
    let fw = forkWith @Dual (Fold Int Bool) 
                      @() foldServer in
    allPositive tr fw
\end{lstlisting}



\section{Algorithms for Type Equivalence}
Algorithms for deciding the equivalence of types are intricately tied to the computational power and expressiveness of the underlying type system: the more expressive the type system is, the more sophisticated the algorithm will be.

%\todo{note type checking in system f is undecidable.}


\begin{figure}[h]
  \begin{align*}
    \typec T \grmeq & \function TT
    %\grmor \tbananas{l_i}{T_i} 
    % \grmor \Unit 
    \grmor  \foralltinfix\alpha\kind T 
    \grmor \typec{\alpha}
    \grmor \tmuinfix{\alpha}{\kind}{T} 
  \end{align*}
\end{figure}

The syntax above inherites from System $F$ variable names $\typec\alpha$, type quantification 
$\foralltinfix\alpha\kind T$ and functions $\function TU$. With the addition of recursion $\tmuinfix{\alpha}{\kind}{T}$, we arrive at System $\FMu$. %In said system, two types are equivalent if they are unfolded versions of each other. For example, the type $\mu\alpha.\alpha$ is equivalent to $\alpha(\mu\alpha.\alpha)$.[ref] 


\begin{figure}[h]
  \begin{align*}
  \typec T \grmeq & (\FMu)
    \grmor \tabs\alpha\kind T
    \grmor \tapp TT 
  \end{align*}
\end{figure}

With the introduction of type abstractions $\tabs\alpha\kind T$ and applications $\tapp TT $, we arrive at a higher-order version, denoted with $\omega$, of System $\FMu$. System $\FMu$'s computational power is akin to finite-state automata. [ref] However, if we raise such system to a higher-order version of itself, its' computational power would be at least as expressive as deterministic pushdown automata for which known equivalence algorithms are
notoriously impractical.  [ref]

%Building upon System $\FMu$, introducing (regular) session types with send/receive operations, choices, and $\End$ type, we arrive at System $\FMuDot$. 

\begin{figure}[h]
  \begin{align*}
    \typec T \grmeq & (\FMu)
    \grmor{} \MSGn T
    \grmor{} \tchoice{l_i}{T_i}
    \grmor \End
    \grmor{} \semit TT 
    \grmor \Skip
  \end{align*}
\end{figure}

Building upon System $\FMu$, introducing context-free session types with sequential composition and type $\Skip$, we arrive at System $\FMuSemi$. Two session types are considered equivalent if they describe exactly the same communication protocol, even if they are not identical syntactically. Thiemann and Vasconcelos proved that type equivalence of context-free session types is decidable [ref] by reducing the problem to the verification of bisimulation for Basic Process Algebra (BPA). It is also known the proof of equivalence between grammars in GNF and BPA processes. With these results,  Almeida et al. [ref] decides the equivalence of context-free session types by reducing the problem to the bisimilarity of simple grammars. The algorithm is divided in three phases:
\begin{itemize}
    \item Translating types into simple grammars;
    \item Pruning unreachable symbols;
    \item Exploring a decision tree: two types are equivalent if during this phase we are able to find an empty node; otherwise,
    the types are not equivalent.
\end{itemize}

An higher-order version of this system, $\FMuSemiOmega$, would still be as expressive as deterministic pushdown automata. However, Poças et al. [ref] proved that, for a small subset of the language where recursion is limited to kind $*$, type equivalence is still representable by simple grammars. Combining this notorious notion and Almeida's algorithm to check if two types are equivalent, we are able to elevate FreeST's type system to a higher-order setting.

%\todo{figure: systems and their computational models.}

%\input{tex/fig-systems.tex}

\section{Type Operators}

A type system is described as higher-order if it supports \textit{type-level functions}, i.e., if it acts upon types and produce even more complex types. Such systems are often realized through mechanisms such as type classes in Haskell or implicits in Scala.[ref]

\lstinline{data List a = Empty | Cons a (List a)}

This Haskell code represents a \lstinline{List}---a type constructor that takes a type \lstinline{a} and returns a new type \lstinline{List a}---which represents a list of elements of type \lstinline{a}. Therefore, the type \lstinline{List} operates on types, that means, when type \lstinline{a} is replaced by another type (let us say $\Int$) the constructor returns \lstinline{List Int}. While type constructors take (concrete) types as inputs, higher-order kinded types operate one level further. They are type operators which take type constructors themselves as inputs. 

%\todo{show ghci :k []}
%The kind of a type can be either a $\skind$, refering to a concrete type such as $\Int$ or $String$, a kind * -> * which represents a type constructor like a $List$ or the monad $Maybe$. 

%\todo{show ghci :k Maybe}\\
A \textit{functor}, a type class where types can be mapped over, would be an example of a higher-order kinded type.

\lstinline{class Functor f where fmap :: (a -> b) -> f a -> f b}

In this example, the method \lstinline{fmap} takes two arguments, a function and a functor type \lstinline{f a}, and returns a new type \lstinline{f b} from mapping the first argument to each value in \lstinline{f a}.

Type classes, in Haskell, enable polymorphism by defining a set of operations that can be implemented for various types. A \textit{type class} is a higher-order abstraction that operates on types rather than values.

\lstinline{class Eq a where (==) :: a -> a -> Bool}

The example above represents \lstinline{Eq}, a type class that defines equality for any type \lstinline{a}. Type classes emerged from the need to deal with ad-hoc polymorphism, also known as overloading, providing a flexible structure to manage polymorphic operations. 
\textit{Ad-hoc polymorphism} refers to the ability of a function or operator to behave differently based on the type of its arguments, that means a function can have different implementations based on the types of its parameters and the compiler will choose the correct implementation based on the types of arguments passed.
While, \textit{Parametric polymorphism} refers to the ability of a function or a data type to be written generically so that it can handle values of any type, without type-specific implementations. For instance, in Haskell, the identity function can be written as, \lstinline{id :: a -> a id x = x}, where given any input \lstinline{x}, returns the same type. This function works generically as it does not matter which type \lstinline{x} has.

%\todo{comparison between oCaml and Haskell.}

A common ad-hoc polymorphism example would be addition through the $+$ operator. In oCaml, the $+$ operator does not allow overloading, that is, it only works to perform the addition of integer values. To perform addition of floating-point numbers a seperate operator must be used---the $+.$ operator.

In contrast, Haskell chooses to offer overloading of its' $+$ operator through the use of type classes. This operator works for both integer and floating-point addition or any type that is an instance of the $Num$ type class.

Scala’s implicits notion have a similar function to haskell's type classes, where the compiler ensures the correctness of these operations based on resolving these implicit types. %The code provided below is the equivalent type class \lstinline{Eq} implemented in Scala: \todo{scala code.}

\todo{introduce ocaml}
A list is an ordered sequence of elements. 
\begin{lstlisting}
    # [1; 2; 3];;
    - : int list = [1; 2; 3]
\end{lstlisting}
This list has three elements, seperated by $(;)$ and its type is \lstinline{int list}.

\begin{lstlisting}
    # [];;
    - : 'a list = []
\end{lstlisting}
Notice how the empty list has type \lstinline{'a list}? We don't know the actual type of the element \lstinline{a}, since the list is empty.

Let's write a function that calculates the length of a list. Keeping in mind that this must work for any type of list. 

\begin{lstlisting}
    # let rec length l =
        match l with
        | [] -> 0
        | _ :: t -> 1 + length t;;
\end{lstlisting}

Here's what happens when we run the function \lstinline{length} with the two lists from the previous example.

\begin{lstlisting}
    # length [1; 2; 3];;
    - : int = 3
    # length [[]];;
    - : int = 1
\end{lstlisting}

What is the type of function \lstinline{length}? How does it work for both an \lstinline{int list} and \lstinline{'a list}?

\begin{lstlisting}
    val length : 'a list -> int = <fun>
\end{lstlisting}

\lstinline{length} takes a list of type \lstinline{'a list} where the variable \lstinline{a} can be instantiated with anything. Then, in the code, the pattern \lstinline{ _ :: t} discards the head of the list as its' type is not relevant to the implementation of the function. This is a simple example of a polymorphic function.

We might wish to apply a function to each element in a list, yielding a new one.

\begin{lstlisting}
    # let rec map f l =
        match l with
        | [] -> []
        | h :: t -> f h :: map f t;;
    val map : ('a -> 'b) -> 'a list -> 'b list = <fun>
\end{lstlisting}

This map function, given a function of type $'a -> 'b$ and a list of $'a$, will build a list of $'b$. This is an example of a higher-order function. 

%\begin{lstlisting}# map (fun x -> x * 2) [1; 2; 3];;- : int list = [2; 4; 6]\end{lstlisting}

%\todo{list has a standard module in ocaml with several useful functions.}
\todo{p. context}

Type classes in Haskell and modules in OCaml represent two distinct approaches to program abstraction and component organization. Type classes in Haskell primarily serve \textit{ad-hoc polymorphism}. They enable you to define behavior that can work across multiple types while maintaining type safety. 
In contrast, OCaml's module system focuses on explicit program structuring and strong data abstraction. 

\begin{lstlisting}
class Show a where
    show :: a -> String

instance Show Int where
    show = Data.Text.pack . show
\end{lstlisting}

\begin{lstlisting}
module type SHOW = sig
    type t
    val show : t -> string
end

module IntShow : SHOW with type t = int = struct
    type t = int
    let show = string_of_int
end
\end{lstlisting}
\todo{caption: Type classes Vs. Modules: Show}

The key differences between the two approaches reside in instance resolution and multiple implementations. While Haskell automatically resolves instances based on types (since type classes are restricted to a singleton instance), oCaml requires explicit module application because it supports multiple possible implementations.

\begin{lstlisting}
    main = print $ show (42 :: Int) --haskell
    let () = print_endline (IntShow.show 42) --oCaml
\end{lstlisting}
\todo{caption: Type classes Vs. Modules: instance resolution}

The trade-off between these approaches focuses on either convenience or explicit control, with each system optimizing for different use cases and programming styles. Nevertheless, an harmonious approach combining type classes and modules was provided by Robert Harper et al. \todo{ref: Modular Type Classes}.

\todo{p. context}

Type classes went on to influence how Generics work in Java. 
\begin{lstlisting}
public static <T extends Comparable<T>> T min (T x, T y) {
    if (x.compare(y) < 0) 
        x; 
    else 
        y; }

min :: Ord a => a -> a -> a
min x y  = if x < y then x else y       
\end{lstlisting}
If $\TT$ extends the interface \lstinline|Comparable<T>|, which is parameterized over the same type variable, is equivalent to say a type variable belongs to a type class in haskell.

Function min is only valid if $a$ belongs to type class $Ord$, because the operation $<$ is only defined for types of $Ord$ instance.
\todo{show phil wadler graphic about type classes constraints and interfaces.}

\LIMPA