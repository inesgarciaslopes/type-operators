
\chapter{Background and Related Work}

\section{Type Systems}

%Exploring sophisticated type systems and their seamless integration into programming languages is a thoroughly researched field. From System $\FMu$  up to System $\FMuOmega$ , how far can we go until these systems are no longer suitable for compilers.

Type systems are a fundamental tool in programming language theory, providing a framework to categorize and constrain the behavior of programs, while types define the kind of data a program manipulates, e.g., integers, booleans, strings. 

Type systems manage a program's data types through type checking, which can be classified as either static---occurs at compile time, where the types of all variables and expressions are known and checked before the program runs---or dynamic---occurs at run-time, where the types are checked as the program executes. 

\todo{p. ligação}
Type equivalence establishes the criteria by which two types are equivalent within a programming language. In presence of polymorphism, type equivalence enables functions to work with different types as long as it can determine whether two types are interchangeable without causing runtime erros or unexpected behavior. Type equivalence can be viewed as structural---where types are equivalent if they share the same structure---or nominal---where types are only equivalent if they share the same name.

Over the course of time, type systems have evolved to become more expressive, moving from simple type assignments to more powerful systems that support polymorphism, recursion, and structured communication patterns.

System $F$, also called the polymorphic lambda calculus, extends the simply typed lambda calculus with \textit{parametric polymorphism}, which allows functions to be written generically and applied to arguments of any type. [ref] In the simply typed lambda calculus, every function has a concrete type. For instance, a function that operates on integers has the type $\function \Int \Int$. However, in order to express a function that operates on a lists of arbitrary types, we would need a separate function for each of the types in the list. To overcome this limitation, System $F$ allowed functions to be polymorphic. For example, the identity function, written $\lambda X. \lambda x:X. x$, returns its argument unchanged, working uniformly for any type---and when instantiated to $\Int$, the result is the identity function on integers, whereas when applied to $Bool$, the result is the identity function on booleans. This is possible through the introduction of type \textit{abstractions}---functions are parameterized by types---and type \textit{applications}---types are passed as arguments to functions.

While System $F$ is a powerful system for expressing parametric polymorphism, it lacks a direct way to express recursive types, which are essential for defining more complex structures and functions that rely on self-reference. Recursive types are particularly important for defining data structures like lists, trees, and infinitely repeating processes.

System $\FMu$ comes as an extension of System $F$ with the addition of \textit{recursion}, denoted by $\mu X.T$, which allows a type $\TT$ to refer to itself through the variable $X$. When adding recursion, type systems must choose how to approach recursive types: a type can be either \textit{equirecursive} or \textit{isorecursive}.
The difference lies on the relation between the type and its' (one-step) unfold. Are $\mu X.T$ and its' unfold ,$T. \mu X.T$, the same type? Equirecursive types say yes. They represent the same infinite tree and therefore are interchangeable when type checking. However, implementing such type checking algorithms requires additional work and attention to guarantee termination. On the other hand, isorecursive types say they are different. Therefore, they are not interchangeable but only isomorphic. 

By allowing recursion at the type level, System $\FMu$ significantly increases the expressiveness of the type system, making it capable of representing potentially infinite structures. However, now care must be taken to ensure that recursive functions terminate, which leads to type systems often incorporating additional rules or constraints to ensure \textit{termination}. Without guarantees of termination, recursive types could lead to non-terminating computations, i.e., infinite recursions, which can make programs unreliable.  

%\todo{note about grammar, pushdown automata, corresponding to the system.}

System $\FMuSemi$ builds on top of System $\FMu$ by incorporating \textit{session types} into the type system. This extension is designed to model structured communication between concurrent processes, ensuring that communication follows a well-defined protocol. 

\section{Session Types}

Session types offer a formal way to describe communication protocols. They ensure that all participants in a communication process adhere to the agreed protocol, improving both safety and expressiveness. This concept emerged in the early 1990s from the fields of process calculi and type theory, particularly building upon Milner's work on the pi-calculus.[ref] Its main purpose was to bring type-level guarantees to communication protocols.

In a programming language, \textit{types} describe the structure of data (e.g., integers, strings) and session types extend this idea to describe communication patterns. They define the order and type of messages exchanged during an interaction, through a communication channel. 
The following simple protocol is finite: a process might want to send an integer, then receive an integer and finally terminate. This protocol can be described by the session types $S = !\Int.?\Int.\End$---we first send an integer, followed by receiving an integer and finally terminate the session through the type $\End$, which closes the communication channel. The order in which the messages (types) are sent is guaranteed through a sequential composition expressed by the $.$ operator.

Communication typically involves two parties---a sender and a receiver---and for a protocol to function correctly, the session types of these parties must be dual. \textit{Duality} is the relationship between two session types that allows them to correctly engage in a protocol. For any session type describing one side of the communication (let us say the client), there is a dual session type that describes the other side (the server).  For example, the session type $S = \OUTn\Int$ describes sending an integer and its dual session type is to receive an integer, $\dual{S} = \INn\Int$.  

Some, more advanced, communication patterns involve branching, where a process might choose, from a set of choices, how to continue the communication. 

$\intchoice\rchannel{isEven}{!Int.?Bool.End}{isZero}{!Int.?Bool.End}$

The previous type represents a protocol (from the client perspective) that offers two operations on integers: it checks whether an integer is even or odd, and it checks whether an integer is zero. Session types are able to express such protocols by offering choice operations---either internal, $\&$, or external, $+$---to the client, which in turn selects how to proceed with the communication: if the client wants to check if an integer is even, it must select the branch $isEven$.



One of the key advantages of session types is that they enable \textit{type-safe communication}. This means that at compile time, the system can check whether the communication patterns follow the prescribed protocol, preventing errors like sending a message of a wrong type. Session types can also help ensure \textit{deadlock freedom}, meaning the system avoids situations where two parties wait indefinitely for each other to send or receive a message.

Type equivalence in session types is the equivalence of binary trees. \todo{elaborate.}

Session types also have limitations---they are tail recursive---not being able to describe expressive types that refer to themselves at any given point of a sequential composition rather than at the end. For instance, the type $ \typec{\mu S} .\OUTn\TT.\typec{S}$, represents adding $\OUTn\TT$ to the tail $\OUTn\TT\OUTn\TT\OUTn\TT...\typec{\mu S}.\OUTn\TT.\typec{S}$ continuously until the session terminates. 

The lack of expressiveness with the increasing complexity of communication protocols in modern systems lead us to context-free session types.

\section{Context-free Session Types}

Context-free session types break free from tail recursion by introducing the sequential composition operator $\Semi$ and the type $\Skip$---neutral element of sequential composition---which represents a protocol with no actions. For instance, one might choose to write $S;!T$ or $!T;S;!T$ where recursion is found in the head or middle of the type. 

With context-free session types, the lema/theorem about tree equality is not true.
For example, types $\Skip\Semi\TT$ and $\TT$ are equivalent but the same is not true for the equivalence of the trees they represent. 

\begin{center}
\begin{tikzpicture}
    \matrix (m) [matrix of math nodes, nodes in empty cells,
                 row sep=2em, column sep=3em,
                 nodes={anchor=center}]
    {
        & \Semi & \\
        \Skip & & \typec{T} \\
    };

    \draw[->] (m-1-2) -- (m-2-1); % \; to skip
    \draw[->] (m-1-2) -- (m-2-3); % \; to T
\end{tikzpicture}
\end{center}

Also, one could naively think the problem lies solely on the neutral element $\Skip$ but such saying is not true: $\TT\Semi(\typec{U}\Semi\typec{V})$ and $(\TT\Semi\typec{U})\Semi\typec{V}$ are equivalent, but their trees are not. 

\begin{center}
\begin{tikzpicture}
    \matrix (m) [matrix of math nodes, nodes in empty cells,
                 row sep=2em, column sep=3em,
                 nodes={anchor=center}]
    {
        & \Semi && \\
        \typec{T} & & \Semi &\\
        & \typec{U} & & \typec{U}\\
    };

    \draw[->] (m-1-2) -- (m-2-1); 
    \draw[->] (m-1-2) -- (m-2-3); 
    \draw[->] (m-2-3) -- (m-3-2); 
    \draw[->] (m-2-3) -- (m-3-4); 
\end{tikzpicture}
\end{center}

\begin{center}
\begin{tikzpicture}
    \matrix (m) [matrix of math nodes, nodes in empty cells,
                 row sep=2em, column sep=3em,
                 nodes={anchor=center}]
    {
        &&  \Semi  \\
        & \Semi & & \typec{V}\\
        \typec{T} &&  \typec{U}\\
    };

    \draw[->] (m-1-3) -- (m-2-2); 
    \draw[->] (m-1-3) -- (m-2-4); 
    \draw[->] (m-2-2) -- (m-3-1); 
    \draw[->] (m-2-2) -- (m-3-3); 

\end{tikzpicture}
\end{center}

\todo{put the trees side by side and add caption.}

%The recursive type $\tmuinfix{\alpha}{\skind}{\extchoice\rchannel{\leafl}{\Skip}{\nodel}{\alpha\Semi\ \INp\Int\Semi\ \alpha}}\Semi\End_{\typec{?}}$ describes a protocol for safely streaming integer trees on a channel. The channel presents an external choice $\extchoice$ with two labels: if the continuation of the channel is $\leafl$, then no communication occurs but the channel is still open for further composition whereas, if the continuation of the channel is $\nodel$, then we have a left subtree, followed by an integer and a right subtree. When the whole tree is received, the channel is closed. 

%It is also important to distinguish type $\End_{\typec{?}}$ from $\Skip$---the former represents the closure of a channel, $\typec{?}$ standing for either $\Wait$ or its' dual $\Close$, where no further communication is possible, while the latter allows continuing the communication where its' dual is himself.

Context-free session types are more expressive than their regular counterparts, covering a wider range of communication protocols and being representable by \textit{context-free grammars}.
Grammars can be specified by tuples of the form $(\mathcal{T, N}, X, \mathcal{R})$, where: 
\begin{enumerate}
    \item $\mathcal{T}$ is a finite set of terminal symbols such as $a, b, c$; 
    \item $\mathcal{N}$ is a finite set of non-terminal symbols, $X, Y, Z$;
    \item $X$ is the starting symbol. $X$ must be an element of $\mathcal{N}$, $X\in\mathcal{N}$;
    \item $\mathcal{R}$ is a finite set of productions, where $P \subseteq N \times (T \cup N)^*$. 
\end{enumerate}
A production rule in $\mathcal{R}$ is written as $X \rightarrow \sigma$: the left side of the arrow must be a non-terminal, $X\in\mathcal{N}$, while the right side must be a word, such that $\sigma\in(\mathcal{N}\cup\mathcal{T})^*$. Also, $\sigma$ can be the empty word. We are particularly interested in simple grammars in Greibach normal form [ref]. Grammars are in \textit{Greibach normal form} if production rules take form as $X \rightarrow a\gamma$, where $X\in\mathcal{N}$, $a\in\mathcal{T}$ and $\gamma\in\mathcal{N}^*$. Grammars in GNF are \emph{simple} when for every non-terminal and terminal symbol there is at most one production $X \rightarrow a\gamma$ [ref].

These type systems prove interesting to implement since they closely represent programs. Therefore, we want to incorporate these type systems into programming languages.

\section{The FreeST Programming Language}
FreeST [ref], a concurrent functional programming language based on system $F^{\mu;}$, is regulated by context-free session types. Resembling Haskell's syntax, FreeST offers primitives to create channels and communicate trough them.

Typically in programming languages, a value can be used as many times as needed. However, FreeST uses a linear type system: a resource may be used exactly once---represented by $1$---or unrestrictely, meaning a resource can be used zero or more times---represented by a $*$. Session type channels are linear and must be used exactly once. Therefore, linear programming languages help ensure the channels protocols are fulfilled. 

It is also important to note that these channels are heterogeneous: $\OUTn\Int\Semi\INn\Int$ is undoubtedly a session type, while $\Bool\rightarrow\Bool$ is a functional type but what about the polymorphic variable $\alpha$? 
The answer relies on FreeST's kinding system. Kinds are pairs composed of a multiplicity and a base kind. Multiplicities control the number of times a value may be used in a given context, making FreeST a linear programming language, and a base kind distinguishs functional types, $\TT$, from session types, $\typec{S}$. Multiplicities and base kinds have an ordering relation denoted by the following lattice. 

\begin{center}
    \begin{tikzpicture}
    % Define matrix
        \matrix (m) [matrix of math nodes, row sep=3em, column sep=3em]
        {
            & \typec{1T} \\
            \typec{*T} && \typec{1S} \\
            & \typec{*S} \\
        };
        % Draw arrows
        \draw[->] (m-1-2) -- (m-2-1) node[midway, above] {};
        \draw[->] (m-2-1) -- (m-3-2) node[near end, below] {};
        \draw[->] (m-1-2) -- (m-2-3) node[midway, above] {};
        \draw[->] (m-2-3) -- (m-3-2) node[near end, below] {};
    \end{tikzpicture}
\end{center}


We use FreeST's syntax freely for the following example for serialisation of a binary tree.

\begin{lstlisting}
data Tree = Leaf | Node Int Tree Tree

type TreeChannel = oplus{Leaf: Skip ,Node: !Int; TreeChannel; TreeChannel}

write: foralla. Tree -> TreeChannel;a -> a
write t c = 
    case t of { 
        Leaf -> select Leaf c, 
        Node x t1 t2 -> select Node c & 
                        send x &  
                        write t1 & 
                        write t2
}

treeSum: foralla. dualof TreeChannel; a -> (Int, a) 
treeSum c = 
    match c with { 
        Leaf c -> (0, c), 
        Node c -> let (x, c) = receive c in
                  let (sl , c) = treeSum c in
                  let (sr, c) = treeSum c in
                  (x + sl + sr , c)
}

\end{lstlisting}

\lstinline{Tree} is a binary tree data type that can be either: a \lstinline{Leaf} (empty node), or a \lstinline{Node} containing an integer value and two subtrees (left and right). \lstinline{TreeChannel} defines a communication protocol type that represents how a tree will be transmitted: if the label \lstinline{Leaf} is selected no communication occurs, but the channel is still open to further communication; if the label \lstinline{Node} is selected then the content of the node is sent, followed by the left subtree and right subtree. 

Then we can implement a function that serializes a tree over a channel: this function takes a \lstinline{Tree} argument and a channel and either selects a Leaf, or selects a Node, sends an integer value and recursively writes the left and right subtree. If we want to sum all the values in a Tree, we can read from a TreeChannel and compute the sum of all the nodes in a Tree. 

\todo{p. to connect to next section}
\todo{more examples: mathserver?}


\section{Algorithms for Type Equivalence}
Algorithms for deciding the equivalence of types are intricately tied to the computational power and expressiveness of the underlying type system: the more expressive the type system is, the more sophisticated the algorithm will be.

%\todo{note type checking in system f is undecidable.}


\begin{figure}[h]
  \begin{align*}
    \typec T \grmeq & \function TT
    %\grmor \tbananas{l_i}{T_i} 
    % \grmor \Unit 
    \grmor  \foralltinfix\alpha\kind T 
    \grmor \typec{\alpha}
    \grmor \tmuinfix{\alpha}{\kind}{T} 
  \end{align*}
\end{figure}

The syntax above inherites from System $F$ variable names $\typec\alpha$, type quantification 
$\foralltinfix\alpha\kind T$ and functions $\function TU$. With the addition of recursion $\tmuinfix{\alpha}{\kind}{T}$, we arrive at System $\FMu$. %In said system, two types are equivalent if they are unfolded versions of each other. For example, the type $\mu\alpha.\alpha$ is equivalent to $\alpha(\mu\alpha.\alpha)$.[ref] 


\begin{figure}[h]
  \begin{align*}
  \typec T \grmeq & (\FMu)
    \grmor \tabs\alpha\kind T
    \grmor \tapp TT 
  \end{align*}
\end{figure}

With the introduction of type abstractions $\tabs\alpha\kind T$ and applications $\tapp TT $, we arrive at a higher-order version, denoted with $\omega$, of System $\FMu$. System $\FMu$'s computational power is akin to finite-state automata. [ref] However, if we raise such system to a higher-order version of itself, its' computational power would be at least as expressive as deterministic pushdown automata for which known equivalence algorithms are
notoriously impractical.  [ref]

%Building upon System $\FMu$, introducing (regular) session types with send/receive operations, choices, and $\End$ type, we arrive at System $\FMuDot$. 

\begin{figure}[h]
  \begin{align*}
    \typec T \grmeq & (\FMu)
    \grmor{} \MSGn T
    \grmor{} \tchoice{l_i}{T_i}
    \grmor \End
    \grmor{} \semit TT 
    \grmor \Skip
  \end{align*}
\end{figure}

Building upon System $\FMu$, introducing context-free session types with sequential composition and type $\Skip$, we arrive at System $\FMuSemi$. Two session types are considered equivalent if they describe exactly the same communication protocol, even if they are not identical syntactically. Thiemann and Vasconcelos proved that type equivalence of context-free session types is decidable [ref] by reducing the problem to the verification of bisimulation for Basic Process Algebra (BPA). It is also known the proof of equivalence between grammars in GNF and BPA processes. With these results,  Almeida et al. [ref] decides the equivalence of context-free session types by reducing the problem to the bisimilarity of simple grammars. The algorithm is divided in three phases:
\begin{itemize}
    \item Translating types into simple grammars;
    \item Pruning unreachable symbols;
    \item Exploring a decision tree: two types are equivalent if during this phase we are able to find an empty node; otherwise,
    the types are not equivalent.
\end{itemize}

An higher-order version of this system, $\FMuSemiOmega$, would still be as expressive as deterministic pushdown automata. However, Poças et al. [ref] proved that, for a small subset of the language where recursion is limited to kind $*$, type equivalence is still representable by simple grammars. Combining this notorious notion and Almeida's algorithm to check if two types are equivalent, we are able to elevate FreeST's type system to a higher-order setting.

%\todo{figure: systems and their computational models.}

%\input{tex/fig-systems.tex}

\section{Type Operators}

A type system is described as higher-order if it supports \textit{type-level functions}. Such systems are often realized through mechanisms such as type classes in Haskell or implicits in Scala.

Let's start by looking at kinds: what is a kind? Kinds are essentially the types of types. If we look at values such as $'Hi', True$, their associated types would be $String$ and $Bool$. Nowadays, most programming languages have a third universe that governs over types. We can look at them as types one level up: kinds. If we ask GHCi the kind signature of the types $String$ and $Bool$, we get:

\begin{lstlisting}
    ghci> :k String
    String :: *
    ghci> :k Bool
    Bool :: *
\end{lstlisting}

Kind $\kast$ is the kind of all \textit{proper types}. What about the kind of a complex type such as the Haskell data type \lstinline|Maybe|? This type is defined in Haskell as:

\begin{lstlisting}
data Maybe a = Nothing | Just a
\end{lstlisting}

\lstinline|Maybe| is a type operator, that given a type \lstinline|a| of kind $\kast$ creates another type \lstinline|Maybe a|---either Nothing or just the element \lstinline|a|---of kind $\kast$. Therefore, \lstinline|Maybe| has kind $\karrow{\kast}{\kast}$. When applied to $String$ and $Bool$, \lstinline|Maybe a| returns a concrete type \lstinline|Maybe String| and \lstinline|Maybe Bool| respectively.

\begin{lstlisting}
    ghci> :k Maybe
    Maybe :: * -> *
    ghci> :k Maybe String
    Maybe String :: *
    ghci> :k Maybe Bool
    Maybe Bool :: *
\end{lstlisting}
Another example of a type operator is the constructor \lstinline|List|. 

\lstinline{data List a = Empty | Cons a (List a)}\\
\lstinline{List} represents a type operator that takes a type \lstinline{a} and returns a new type \lstinline{List a}, which represents a list of elements of type \lstinline{a}. Therefore, the type \lstinline{List} operates on types, that means, when type \lstinline{a} is replaced by another type (let us say $\Int$) the constructor returns \lstinline{List Int}. The kind of \lstinline|List| is also $\karrow\kast\kast$. 

\todo{caption: relation between kinds, types and values.}

\begin{center}
    \begin{tikzpicture}
    % Define matrix
        \matrix (m) [matrix of math nodes, row sep=3em, column sep=1em]
        {
            kinds && \kast && \karrow{\kast}{\kast}\\
            types & String & Bool & Maybe String & Maybe \\
            values & 'Hi' & True\\
        };
        % Draw arrows
        \draw[-] (m-1-3) -- (m-2-2) node[midway, left] {};
        \draw[-] (m-1-3) -- (m-2-3) node[midway, left] {};
        \draw[-] (m-1-3) -- (m-2-4) node[midway, left] {};
        \draw[-] (m-1-5) -- (m-2-5) node[midway, right] {};
        \draw[-] (m-2-2) -- (m-3-2) node[midway, left] {};
        \draw[-] (m-2-3) -- (m-3-3) node[midway, right] {};
    \end{tikzpicture}
\end{center}

What about types that take type operators as arguments and return another type? A \textit{functor}, a type class where types can be mapped over, would be an example of a higher-order kinded type. The kind of a Functor is $\karrow{(\karrow\kast\kast)} {Constraint}$, which means Functor takes a type operator like \lstinline|Maybe| and returns a $constraint$ kind. %Constraint is the kind of class constraints – it covers anything that can appear on the left side of the arrow when defining a type.


Type classes, in Haskell, enable polymorphism by defining a set of operations that can be implemented for various types. A \textit{type class} is a higher-order abstraction that operates on types rather than values.

\lstinline{class Eq a where (==) :: a -> a -> Bool}

The example above represents \lstinline{Eq}, a type class that defines equality for any type \lstinline{a}. Type classes emerged from the need to deal with ad-hoc polymorphism, also known as overloading, providing a flexible structure to manage polymorphic operations. 
\textit{Ad-hoc polymorphism} refers to the ability of a function or operator to behave differently based on the type of its arguments, that means a function can have different implementations based on the types of its parameters and the compiler will choose the correct implementation based on the types of arguments passed.
While, \textit{Parametric polymorphism} refers to the ability of a function or a data type to be written generically so that it can handle values of any type, without type-specific implementations. For instance, in Haskell, the identity function can be written as, \lstinline{id x = x}, where given any input \lstinline{x}, returns the same type. This function works generically as it does not matter which type \lstinline{x} has. In fact, the type signature of the identity function is \lstinline|id :: a -> a|.

%\todo{comparison between oCaml and Haskell.}

A common ad-hoc polymorphism example would be addition through the $+$ operator. In oCaml, the $+$ operator does not allow overloading, that is, it only works to perform the addition of integer values. To perform addition of floating-point numbers a seperate operator must be used---the $+.$ operator. In contrast, Haskell chooses to offer overloading of its' $+$ operator through the use of type classes. This operator works for both integer and floating-point addition or any type that is an instance of the $Num$ type class.

%Scala’s implicits notion have a similar function to haskell's type classes, where the compiler ensures the correctness of these operations based on resolving these implicit types. %The code provided below is the equivalent type class \lstinline{Eq} implemented in Scala: \todo{scala code.}

\todo{p. context + introduce ocaml}

Type classes in Haskell and modules in OCaml represent two distinct approaches to program abstraction and component organization. Type classes in Haskell primarily serve \textit{ad-hoc polymorphism}. They enable you to define behavior that can work across multiple types while maintaining type safety. 
In contrast, OCaml's module system focuses on explicit program structuring and strong data abstraction. 

\begin{lstlisting}
class Show a where
    show :: a -> String

instance Show Int where
    show = Prelude.show
\end{lstlisting}

The code above represents a type class \lstinline|Show| for a type \lstinline|a|, where the \lstinline|show| method converts a type \lstinline|a| into a String. The equivalent code in OCaml, would look like this:
\begin{lstlisting}
module type SHOW = sig
    type t
    val show : t -> string
end

module IntShow : SHOW with type t = int = struct
    type t = int
    let show = string_of_int
end
\end{lstlisting}
\todo{caption: Type classes Vs. Modules: Show}

The key differences between the two approaches reside in instance resolution and multiple implementations. While Haskell automatically resolves instances based on types (since type classes are restricted to a singleton instance), oCaml requires explicit module application because it supports multiple possible implementations.

\begin{lstlisting}
    main = print $ show (42 :: Int) --haskell
    let () = print_endline (IntShow.show 42) --oCaml
\end{lstlisting}
\todo{caption: Type classes Vs. Modules: instance resolution}

The trade-off between these approaches focuses on either convenience or explicit control. Nevertheless, an harmonious approach combining type classes and modules was provided by Robert Harper et al. \todo{ref: Modular Type Classes}.

\todo{p. context}

Type classes went on to influence how Generics work in Java. Generics are an interface or class that takes a number of type parameters, which are written within angle brackets, that must be declared when we create a new instance of the said class.

\begin{lstlisting}
    List<String> words = new ArrayList<String>();
    words.add('Hello ');
    words.add('world!');
    String s = words.get(0)+words.get(1);
    assert s.equals('Hello world!');
\end{lstlisting}

This code declares a list of Strings called \lstinline|words|---an instance of \lstinline|ArrayList|---and adds two strings to the list. Then, we chek if the declared \lstinline|String s| is the same as the concatenation of the two strings in \lstinline|words|.
We can see that \lstinline|ArrayList<E>| implements the interface \lstinline|List<E>| and we instantiate the type parameter \lstinline|E| with \lstinline|String|. Without Generics, we would ommit the type parameters and explicitly cast the type whenever needed. In this case, we need to know that the elements of this list are of type \lstinline|String| and cast when extracting the elements from the list, \lstinline|(String)words.get(0)|.
\begin{lstlisting}
    List words = new ArrayList();
    words.add('Hello ');
    words.add('world!');
    String s = ((String)words.get(0))+((String)words.get(1)) 
    assert s.equals(Hello world!');
\end{lstlisting}

\todo{this is possible because of type erasure.}

\todo{show wadler's graphic about type classes constraints and interfaces. (maybe)}

\LIMPA